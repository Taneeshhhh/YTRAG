{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8cd5520",
   "metadata": {},
   "source": [
    "# Data ingestion -> chunking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "488eb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from langchain_community.document_loaders import PyMuPDFLoader,PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08fbc2b",
   "metadata": {},
   "source": [
    "### PDF doc cleaning and formating before chunking and during ingestion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f767e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_pdf_text(text):\n",
    "    # Remove multiple newlines\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "    # Replace single newline inside paragraphs with space\n",
    "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)\n",
    "\n",
    "    # Remove standalone page numbers\n",
    "    text = re.sub(r'^\\d+\\s*$', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove excessive spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c846be8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process all PDF in a Directory\n",
      "Found 2 PDF files to process\n",
      "\n",
      "Processing:MIT-UG Academic HandBook 2025 -2026 - Revised.pdf\n",
      "loaded 409 pages\n",
      "\n",
      "Processing:OSDL manual.pdf\n",
      "loaded 59 pages\n",
      "\n",
      "Total documents loaded : 468\n"
     ]
    }
   ],
   "source": [
    "### read all the pdf in the dir \n",
    "\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF in a Directory\"\"\"\n",
    "    all_Documents=[]\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    pdf_files=list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    # a pdf file will contain many documents in it;\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing:{pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyMuPDFLoader(str(pdf_file))\n",
    "            documents=loader.load()\n",
    "\n",
    "            for doc in documents:\n",
    "                doc.page_content = clean_pdf_text(doc.page_content)\n",
    "                doc.metadata['source_file']=pdf_file.name\n",
    "                doc.metadata['file_type']='pdf'\n",
    "            all_Documents.extend(documents)\n",
    "            print(f\"loaded {len(documents)} pages\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error {e}\")\n",
    "    print(f\"\\nTotal documents loaded : {len(all_Documents)}\")\n",
    "    return all_Documents\n",
    "print(process_all_pdfs.__doc__)\n",
    "docs = process_all_pdfs(\"../data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7532c2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A constituent unit of MAHE, Manipal) MANIPAL INSTITUTE OF TECHNOLOGY MANIPAL 2025-26 B.Tech. 2025 - 26 Academic Programme Hand\u0000book\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a95b8b7",
   "metadata": {},
   "source": [
    "# CHUNKING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab11e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## chunking : splitting file to get smaller chunk for better data retrival\n",
    "def chunk_docs(documents,chunk_size=750,chunk_overlap =150):\n",
    "    \"\"\"Split documents imto smaller chunks \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\",\"\\n\",\" \",\"\"]\n",
    "    )\n",
    "    split_docs=text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    #show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample Chunk:\")\n",
    "        print(f\"Content :{split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"metadata:{split_docs[0].metadata}\")\n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "229fe248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 468 documents into 3397 chunks\n",
      "\n",
      "Example Chunk\n",
      "Content :(A constituent unit of MAHE, Manipal) MANIPAL INSTITUTE OF TECHNOLOGY MANIPAL 2025-26 B.Tech. 2025 - 26 Academic Programme Hand\u0000book...\n",
      "metadata:{'producer': 'Corel PDF Engine Version 23.5.0.506', 'creator': 'CorelDRAW 2021', 'creationdate': '2025-07-08T11:23:57+05:30', 'source': '..\\\\data\\\\pdf_files\\\\MIT-UG Academic HandBook 2025 -2026 - Revised.pdf', 'file_path': '..\\\\data\\\\pdf_files\\\\MIT-UG Academic HandBook 2025 -2026 - Revised.pdf', 'total_pages': 409, 'format': 'PDF 1.7', 'title': '', 'author': 'Harish Shetty', 'subject': '', 'keywords': '', 'moddate': '2025-07-09T11:29:33+05:30', 'trapped': '', 'modDate': \"D:20250709112933+05'30'\", 'creationDate': \"D:20250708112357+05'30'\", 'page': 0, 'source_file': 'MIT-UG Academic HandBook 2025 -2026 - Revised.pdf', 'file_type': 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "chunks=chunk_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6808f0f6",
   "metadata": {},
   "source": [
    "## Embedding and vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "599668cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List,Tuple,Dict,Any\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae227783",
   "metadata": {},
   "source": [
    "# Embeddings, Frameworks & Python OOP (RAG Context)\n",
    "\n",
    "---\n",
    "\n",
    "## Libraries Used \n",
    "\n",
    "### numpy \n",
    "- Used for numerical computations. \n",
    "- Handles vectors and matrices. \n",
    "- Embeddings are numerical vectors → NumPy helps manipulate them. \n",
    "\n",
    "---\n",
    "\n",
    "### sentence_transformers \n",
    "- Provides pretrained embedding models. \n",
    "- Converts text → fixed-size dense vector. \n",
    "- Example model: `\"all-MiniLM-L6-v2\"` \n",
    "- Embedding dimension: **384** \n",
    "\n",
    "Example: \n",
    "```python\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "vector = model.encode(\"Hello world\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca748542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding Model all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 609.52it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sucessfully .Embeding Dimention :384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "__main__.EmbeddingManager"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    def __init__(self,model_name:str='all-MiniLM-L6-v2'):\n",
    "        #DOCSTRINGS\n",
    "        \"\"\"\n",
    "        Initialize the Embedding manager\n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "       \n",
    "        \"\"\"\n",
    "        self.model_name=model_name\n",
    "        self.model=None\n",
    "        self._load_model()#it is going to load this model using a protected fuc\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding Model {self.model_name}\")\n",
    "            self.model=SentenceTransformer(self.model_name)\n",
    "            print(f\"Loaded sucessfully .Embeding Dimention :{self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error Loading Model{self.model_name}:{e}\")\n",
    "            raise\n",
    "    def generate_embeddings(self,texts:List[str])->np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "        Args:\n",
    "            texts:List of text Strings to embed\n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts)),embedding_dim)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model Not loaded\")\n",
    "        print(f\"Generating embedding for{len(texts)} texts..\")\n",
    "        embeddings= self.model.encode(texts,show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with Shape:{embeddings.shape}\")\n",
    "        return embeddings\n",
    "    def get_embedding_dimension(self)-> int:\n",
    "        \"\"\"Get the embedding dimension of the model\"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not Loaded\")\n",
    "        return self.model.get_sentence_embedding_dimension()\n",
    "\n",
    "###initiaize the embeddingmanager \n",
    "\n",
    "Embedding_manager=EmbeddingManager()\n",
    "EmbeddingManager\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a8e4ae",
   "metadata": {},
   "source": [
    "## EmbeddingManager Class – Explanation\n",
    "---\n",
    "## Purpose\n",
    "\n",
    "- Wrapper around a HuggingFace SentenceTransformer model.\n",
    "- Loads embedding model once.\n",
    "- Stores it inside object for reuse.\n",
    "- Designed for clean and scalable ML architecture.\n",
    "\n",
    "---\n",
    "\n",
    "## Class Definition\n",
    "\n",
    "```python\n",
    "class EmbeddingManager:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412df35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YTRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
